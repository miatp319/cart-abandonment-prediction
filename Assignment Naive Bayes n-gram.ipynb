{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6a50581",
   "metadata": {},
   "source": [
    "# 1. Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "230bc211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e5903d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions_train = json.load(open('data/symbolised_sessions_training_group27.json', 'r'))\n",
    "labels_train = json.load(open('data/labels_training_group27.json', 'r'))\n",
    "sessions_eval = json.load(open('data/symbolised_sessions_eval_group27.json', 'r'))\n",
    "labels_eval = json.load(open('data/labels_eval_group27.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d34ec04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_featurizer(session, n):\n",
    "    \n",
    "    \"\"\"takes in a list and an integer defining the size of ngrams.\n",
    "     Returns the ngrams of desired size in the input string\"\"\"\n",
    "    \n",
    "    session = ['#']*(n-1) + session + ['+']*(n-1)\n",
    "    ngrams = [tuple(session[i:i+n]) for i in range(len(session)-n+1)]\n",
    "    \n",
    "    return ngrams\n",
    "    \n",
    "\n",
    "def encode_sessions(sessions, n, mapping=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Takes in a list of lists, an integer indicating the character ngrams' size,\n",
    "    and a dictionary mapping ngrams to numerical indices. If no dictionary is passed,\n",
    "    one is created inside the function.\n",
    "    The function outputs a 2d NumPy array with as many rows as there are strings in \n",
    "    the input list, and the mapping from ngrams to indices, representing the columns \n",
    "    of the NumPy array.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not mapping:\n",
    "        all_ngrams = set()\n",
    "        for session in sessions:\n",
    "            all_ngrams = all_ngrams.union(set(ngram_featurizer(session, n)))\n",
    "    \n",
    "        mapping = {ngram: i for i, ngram in enumerate(all_ngrams)}\n",
    "    \n",
    "    X = np.zeros((len(sessions), len(mapping)))\n",
    "    for i, session in enumerate(sessions):\n",
    "        for ngram in ngram_featurizer(session, n):\n",
    "            try:\n",
    "                X[i, mapping[ngram]] += 1\n",
    "            except KeyError:\n",
    "                pass\n",
    "    \n",
    "    return X, mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "933fe2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('#', '#', '#', 1), ('#', '#', 1, 2), ('#', 1, 2, 3), (1, 2, 3, 1), (2, 3, 1, 1), (3, 1, 1, 1), (1, 1, 1, 1), (1, 1, 1, 1), (1, 1, 1, 1), (1, 1, 1, 1), (1, 1, 1, 2), (1, 1, 2, 1), (1, 2, 1, 1), (2, 1, 1, 2), (1, 1, 2, 1), (1, 2, 1, 1), (2, 1, 1, 2), (1, 1, 2, 1), (1, 2, 1, '+'), (2, 1, '+', '+'), (1, '+', '+', '+')]\n",
      "{(1, '+', '+', '+'), (3, 1, 1, 1), (1, 2, 1, '+'), (2, 1, '+', '+'), (2, 3, 1, 1), (1, 2, 3, 1), (1, 2, 1, 1), ('#', '#', 1, 2), (2, 1, 1, 2), (1, 1, 1, 2), ('#', '#', '#', 1), (1, 1, 2, 1), (1, 1, 1, 1), ('#', 1, 2, 3)}\n"
     ]
    }
   ],
   "source": [
    "print(ngram_featurizer(sessions_train[0], 4))\n",
    "print(set(ngram_featurizer(sessions_train[0], 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ff24151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('#', '#', 2, 2): 0, ('#', 1, 2, 2): 1, (4, 1, 2, 4): 2, (2, 3, 1, 4): 3, (1, 2, 1, 1): 4, ('#', '#', 3, 3): 5, ('#', 1, 1, 3): 6, (2, 1, 1, 1): 7, (4, 3, 3, '+'): 8, (1, 4, 3, 1): 9, (4, 4, 3, 4): 10, (1, 3, 1, 4): 11, (1, 1, 2, 3): 12, ('#', 1, 2, 4): 13, ('#', 3, 4, 1): 14, (3, 4, '+', '+'): 15, (1, 2, 1, 3): 16, (3, 1, 1, 2): 17, (1, 2, 4, '+'): 18, (4, 3, 3, 1): 19, (2, 1, 1, 3): 20, (1, 4, 3, 3): 21, (3, 3, 3, 2): 22, ('#', 2, 1, 2): 23, (2, 4, 2, 1): 24, ('#', 4, 1, 4): 25, (2, '+', '+', '+'): 26, (3, 4, 3, 2): 27, ('#', 3, 4, 3): 28, (2, 3, 1, '+'): 29, (2, 1, 4, 2): 30, (2, 3, 4, 4): 31, (3, 1, 2, 2): 32, (1, 2, 4, 1): 33, (3, 1, 1, 4): 34, (4, 3, 3, 3): 35, (2, 2, 2, 1): 36, (3, 3, 3, 4): 37, (4, 4, 1, '+'): 38, (1, 3, 1, '+'): 39, ('#', '#', 1, 1): 40, ('#', 2, 1, 4): 41, (4, 1, 2, 1): 42, (3, 4, 4, 2): 43, (2, 3, 1, 1): 44, (3, 4, 3, 4): 45, (1, 4, 1, '+'): 46, (2, 1, 4, 4): 47, (1, 2, 4, 3): 48, (3, 1, 2, 4): 49, (4, 4, 1, 1): 50, (1, 3, 1, 1): 51, ('#', '#', 2, 1): 52, ('#', '#', 1, 3): 53, ('#', 3, 1, 2): 54, (3, 4, 4, 4): 55, (1, 4, 1, 1): 56, (2, 3, 1, 3): 57, (2, 3, 4, '+'): 58, (4, 1, 4, 3): 59, (3, 1, 1, '+'): 60, ('#', 1, 1, 2): 61, (1, 2, '+', '+'): 62, (1, 3, 4, 2): 63, (4, 4, 1, 3): 64, (1, 3, 1, 3): 65, ('#', 4, 1, 1): 66, ('#', 1, 4, 4): 67, (3, 4, 3, '+'): 68, (1, 4, 1, 3): 69, (1, '+', '+', '+'): 70, (1, 2, 1, 2): 71, (2, 3, 4, 1): 72, (2, 1, 4, '+'): 73, (3, 1, 1, 1): 74, ('#', 1, 1, 4): 75, (2, 1, 1, 2): 76, (1, 3, 4, 4): 77, ('#', 2, 1, 1): 78, (2, 2, 1, 2): 79, (2, 4, 1, 4): 80, (3, 4, 3, 1): 81, (4, 1, 1, 2): 82, (2, 1, 4, 1): 83, (1, 2, 1, 4): 84, (2, 3, 4, 3): 85, (3, 1, 1, 3): 86, (4, '+', '+', '+'): 87, (1, 1, 1, 2): 88, (4, 3, 3, 2): 89, (2, 1, 1, 4): 90, ('#', 2, 1, 3): 91, (2, 2, 1, 4): 92, (3, 4, 3, 3): 93, (3, 1, 4, 4): 94, (4, 1, 1, 4): 95, (3, 2, 1, 2): 96, (2, 1, 4, 3): 97, (1, 2, 4, 2): 98, (2, 3, '+', '+'): 99, (1, 1, 1, 4): 100, (1, 3, 4, '+'): 101, ('#', 1, 4, 1): 102, ('#', '#', 1, 2): 103, (2, 4, 1, '+'): 104, (2, 3, 1, 2): 105, (1, 3, '+', '+'): 106, (3, 2, 1, 4): 107, ('#', 3, 3, 1): 108, (4, 1, 4, 2): 109, (1, 2, 4, 4): 110, (2, 1, '+', '+'): 111, (1, 2, 3, '+'): 112, (1, 3, 4, 1): 113, (1, 1, 4, 2): 114, ('#', '#', 4, 3): 115, ('#', '#', '#', 2): 116, (4, 4, 1, 2): 117, ('#', 1, 4, 3): 118, ('#', '#', 1, 4): 119, (2, 2, 1, '+'): 120, (2, 4, 1, 1): 121, (4, 4, 4, 4): 122, (3, 1, 4, '+'): 123, (4, 1, 1, '+'): 124, (1, 4, 1, 2): 125, ('#', 3, 3, 3): 126, (4, 1, 4, 4): 127, ('#', 1, 3, 4): 128, (3, 3, 1, 3): 129, (1, 1, 1, '+'): 130, (4, 3, 2, 1): 131, (1, 3, 4, 3): 132, (1, 1, 4, 4): 133, (3, 1, '+', '+'): 134, ('#', '#', '#', 4): 135, (4, 4, 1, 4): 136, ('#', 4, 1, 2): 137, (2, 2, 1, 1): 138, (1, 4, 4, 3): 139, (2, 4, 1, 3): 140, (3, 1, 4, 1): 141, (4, 3, 1, 2): 142, (4, 1, 1, 1): 143, ('#', 4, 4, 4): 144, (1, 4, 1, 4): 145, (3, 2, 1, '+'): 146, (2, 3, 4, 2): 147, (2, 1, 3, 4): 148, (1, 1, 1, 1): 149, (1, 2, 3, 3): 150, (3, '+', '+', '+'): 151, (2, 2, 1, 3): 152, (4, 4, 4, '+'): 153, (4, 3, 1, 4): 154, (3, 1, 4, 3): 155, (3, 2, 1, 1): 156, (1, 4, '+', '+'): 157, (4, 1, 1, 3): 158, (4, 1, 4, '+'): 159, (2, 3, 3, '+'): 160, (1, 1, 1, 3): 161, (4, 4, '+', '+'): 162, (1, 1, 4, '+'): 163, (3, 1, 3, 4): 164, (4, 4, 4, 1): 165, (3, 2, 1, 3): 166, (4, 1, 4, 1): 167, ('#', 1, 3, 1): 168, (2, 1, 3, '+'): 169, (2, 3, 3, 1): 170, (1, 3, 3, 2): 171, (1, 1, 4, 1): 172, ('#', '#', 4, 2): 173, ('#', '#', '#', 1): 174, ('#', 3, 2, 1): 175, (3, 3, 2, 1): 176, (4, 4, 4, 3): 177, (4, 3, 1, '+'): 178, ('#', 4, 4, 1): 179, (3, 4, 2, 1): 180, (2, 4, 4, 2): 181, ('#', 1, 3, 3): 182, (2, 1, 3, 1): 183, (3, 3, 1, 2): 184, (2, 3, 3, 3): 185, ('#', 4, 3, 2): 186, (1, 3, 3, 4): 187, (1, 1, 4, 3): 188, ('#', '#', 4, 4): 189, (3, 1, 3, '+'): 190, ('#', '#', '#', 3): 191, (1, 4, 4, 2): 192, (2, 4, 1, 2): 193, (4, 3, 1, 1): 194, ('#', 4, 4, 3): 195, (2, 4, 4, 4): 196, ('#', 3, 3, 4): 197, (2, 1, 3, 3): 198, (3, 3, 1, 4): 199, (4, 1, '+', '+'): 200, (1, 2, 3, 2): 201, (3, 1, 3, 1): 202, ('#', 4, 3, 4): 203, (3, 4, 1, 4): 204, (1, 1, '+', '+'): 205, (2, 1, 2, 4): 206, (4, 1, 3, 3): 207, (1, 4, 4, 4): 208, (3, 1, 4, 2): 209, (4, 3, 1, 3): 210, (1, 2, 3, 4): 211, (1, 3, 3, '+'): 212, (3, 1, 3, 3): 213, (3, 3, 4, '+'): 214, (1, 1, 3, 2): 215, (4, 3, 4, 4): 216, (2, 4, 4, '+'): 217, (3, 3, '+', '+'): 218, (3, 3, 1, '+'): 219, (1, 3, 3, 1): 220, ('#', '#', 4, 1): 221, (3, 3, 4, 1): 222, (3, 4, 1, '+'): 223, (1, 1, 3, 4): 224, (2, 4, '+', '+'): 225, (2, 1, 2, '+'): 226, (2, 3, 2, 1): 227, (1, 4, 4, '+'): 228, (4, 2, 1, '+'): 229, (4, 4, 4, 2): 230, (2, 4, 4, 1): 231, ('#', 1, 3, 2): 232, (3, 3, 1, 1): 233, (2, 3, 3, 2): 234, (4, 1, 2, '+'): 235, (1, 2, 2, 1): 236, ('#', 4, 3, 1): 237, (1, 3, 3, 3): 238, (3, 3, 4, 3): 239, (2, 4, 3, 2): 240, (3, 4, 1, 1): 241, (2, 1, 2, 1): 242, (4, 3, 4, '+'): 243, (1, 4, 4, 1): 244, (4, 2, 1, 1): 245, (4, 4, 3, '+'): 246, (2, 4, 4, 3): 247, (2, 1, 3, 2): 248, (2, 3, 3, 4): 249, (1, 2, 3, 1): 250, (1, 2, 2, 3): 251, (2, 4, 3, 4): 252, (1, 1, 3, '+'): 253, (4, 3, 4, 1): 254, (2, 1, 2, 3): 255, (4, 2, 1, 3): 256, (4, 4, 3, 1): 257, ('#', 1, 2, 1): 258, (4, 1, 2, 3): 259, (3, 1, 3, 2): 260, (1, 1, 3, 1): 261, ('#', '#', 3, 2): 262, (4, 3, 4, 3): 263, (4, 1, 3, 4): 264, (3, 3, 3, '+'): 265, (4, 4, 3, 3): 266, (1, 1, 2, 2): 267, ('#', 3, 1, 4): 268, ('#', 1, 2, 3): 269, (2, 4, 3, '+'): 270, (3, 1, 2, '+'): 271, (1, 1, 3, 3): 272, ('#', '#', 3, 4): 273, (4, 3, '+', '+'): 274, (1, 4, 3, 2): 275, (3, 3, 3, 1): 276, (1, 1, 2, 4): 277, (3, 4, 4, '+'): 278, (2, 4, 3, 1): 279, (3, 1, 2, 1): 280, ('#', 4, 2, 1): 281, (1, 4, 3, 4): 282, (3, 3, 3, 3): 283, (1, 2, 2, 2): 284, (3, 4, 4, 1): 285, ('#', 3, 4, 4): 286, (2, 2, 3, 1): 287, (3, 3, 4, 4): 288, (3, 4, 1, 2): 289, (3, 1, 2, 3): 290, (2, 4, 3, 3): 291, (2, 1, 2, 2): 292, (4, 1, 3, 1): 293, (4, 2, 1, 2): 294, (4, 3, 3, 4): 295, ('#', 2, 2, 1): 296, (1, 1, 2, '+'): 297, ('#', 3, 1, 1): 298, (4, 1, 2, 2): 299, (3, 4, 4, 3): 300, (1, 2, 1, '+'): 301, (4, 4, 2, 1): 302, (1, 3, 2, 1): 303, ('#', '#', 3, 1): 304, ('#', 1, 1, 1): 305, (2, 1, 1, '+'): 306, (4, 2, 1, 4): 307, (1, 4, 3, '+'): 308, (1, 4, 2, 1): 309, (4, 4, 3, 2): 310, (1, 3, 1, 2): 311, (1, 1, 2, 1): 312} "
     ]
    }
   ],
   "source": [
    "Xtrain, mapping = encode_sessions(sessions_train, 4)\n",
    "Xtest, _ = encode_sessions(sessions_eval, 4, mapping=mapping)\n",
    "print(mapping, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c3155f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 1. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 4. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 3.]\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain[0,:])\n",
    "#the same as the matrix above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb656d0",
   "metadata": {},
   "source": [
    "# 2. Train 4-gram NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b741e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit NB classifier.\n",
    "\"\"\"\n",
    "For imbalanced dataset, it is recommended to use ComplementNB\n",
    "\"\"\"\n",
    "from sklearn.naive_bayes import ComplementNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "faca245a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search Results:\n",
      "             mean_test_accuracy  mean_test_f1_score  mean_test_precision  \\\n",
      "param_alpha                                                                \n",
      "0.00001                0.702218            0.516012             0.405612   \n",
      "0.00010                0.702057            0.515877             0.405444   \n",
      "0.00100                0.701961            0.515821             0.405352   \n",
      "0.10000                0.701400            0.515352             0.404774   \n",
      "1.00000                0.700615            0.514646             0.403951   \n",
      "\n",
      "             mean_test_recall  mean_train_accuracy  mean_train_f1_score  \\\n",
      "param_alpha                                                               \n",
      "0.00001              0.709040             0.702458             0.516646   \n",
      "0.00010              0.709040             0.702310             0.516521   \n",
      "0.00100              0.709111             0.702194             0.516424   \n",
      "0.10000              0.709111             0.701713             0.515989   \n",
      "1.00000              0.708968             0.700848             0.515002   \n",
      "\n",
      "             mean_train_precision  mean_train_recall  \n",
      "param_alpha                                           \n",
      "0.00001                  0.405958           0.710329  \n",
      "0.00010                  0.405805           0.710329  \n",
      "0.00100                  0.405684           0.710329  \n",
      "0.10000                  0.405178           0.710239  \n",
      "1.00000                  0.404204           0.709488  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "alpha_list = [0.00001, 0.0001, 0.001, 0.1, 1]\n",
    "param_grid = {'alpha': alpha_list}\n",
    "scorers = {\n",
    "    'accuracy': metrics.make_scorer(accuracy_score),\n",
    "    'precision': metrics.make_scorer(precision_score),\n",
    "    'recall': metrics.make_scorer(recall_score),\n",
    "    'f1_score': metrics.make_scorer(f1_score)\n",
    "}\n",
    "cnb_model=ComplementNB()\n",
    "grid_search = GridSearchCV(cnb_model, param_grid=param_grid, cv=5, scoring=scorers, refit=False, return_train_score=True)\n",
    "grid_search.fit(Xtrain, labels_train)\n",
    "\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "pivot_table = results.pivot_table(index='param_alpha', \n",
    "                                     values=['mean_train_accuracy', 'mean_test_accuracy', \n",
    "                                             'mean_train_precision', 'mean_test_precision',\n",
    "                                             'mean_train_recall', 'mean_test_recall',\n",
    "                                             'mean_train_f1_score', 'mean_test_f1_score'])\n",
    "\n",
    "print(\"Grid Search Results:\")\n",
    "print(pivot_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ce1c268",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The GridSearch Results show that with alpha = 0.01 we have the best F1-score. But this is still quite bad. \n",
    "Now we train the best model on the train set\n",
    "\"\"\"\n",
    "final_cnb_model = ComplementNB(alpha=0.001,fit_prior=True)\n",
    "final_cnb_model.fit(Xtrain, labels_train)\n",
    "Xtest_cnb = final_cnb_model.predict(Xtest)\n",
    "f1_final = metrics.f1_score(labels_eval, Xtest_cnb)\n",
    "acc_final = metrics.accuracy_score(labels_eval, Xtest_cnb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a63ddb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5169767686323977"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5cfd6f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7055053515349612"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f11e50",
   "metadata": {},
   "source": [
    "# 3. Try oversampling methods to deal with imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e1edc6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search Results:\n",
      "                           mean_test_accuracy  mean_test_f1_score  \\\n",
      "param_complementnb__alpha                                           \n",
      "0.00001                              0.693934            0.535855   \n",
      "0.00010                              0.693869            0.535803   \n",
      "0.00100                              0.693821            0.535764   \n",
      "0.10000                              0.693501            0.535504   \n",
      "1.00000                              0.693277            0.535389   \n",
      "\n",
      "                           mean_test_precision  mean_test_recall  \\\n",
      "param_complementnb__alpha                                          \n",
      "0.00001                               0.405673          0.789134   \n",
      "0.00010                               0.405613          0.789134   \n",
      "0.00100                               0.405569          0.789134   \n",
      "0.10000                               0.405271          0.789134   \n",
      "1.00000                               0.405082          0.789349   \n",
      "\n",
      "                           mean_train_accuracy  mean_train_f1_score  \\\n",
      "param_complementnb__alpha                                             \n",
      "0.00001                               0.694390             0.536794   \n",
      "0.00010                               0.694362             0.536771   \n",
      "0.00100                               0.694322             0.536739   \n",
      "0.10000                               0.693970             0.536407   \n",
      "1.00000                               0.693657             0.536176   \n",
      "\n",
      "                           mean_train_precision  mean_train_recall  \n",
      "param_complementnb__alpha                                           \n",
      "0.00001                                0.406237           0.791014  \n",
      "0.00010                                0.406211           0.791014  \n",
      "0.00100                                0.406173           0.791014  \n",
      "0.10000                                0.405831           0.790870  \n",
      "1.00000                                0.405548           0.790942  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The data is highly imbalanced as the essence of the problem. \n",
    "We will try to use 2 methods: SMOTE and ADASYN to deal with imbalanced data and check the result\n",
    "In this step, we use a experimental setting to avoid data leakage when combining SMOTE and cross-validation\n",
    "Reference: https://kiwidamien.github.io/how-to-do-cross-validation-when-upsampling-data.html\n",
    "\"\"\"\n",
    "#ADASYN\n",
    "\n",
    "from imblearn.pipeline import Pipeline, make_pipeline\n",
    "from imblearn import datasets\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "imba_pipeline = make_pipeline(ADASYN(n_neighbors=5, random_state=2727), \n",
    "                                    ComplementNB())\n",
    "param_grid = {\n",
    "    'complementnb__alpha': alpha_list  \n",
    "}\n",
    "\n",
    "grid_imba = GridSearchCV(imba_pipeline, param_grid=param_grid, cv=5, scoring=scorers,\n",
    "                        return_train_score=True,refit=False)\n",
    "smote_grid = grid_imba.fit(Xtrain, labels_train)\n",
    "smote_results = pd.DataFrame(smote_grid.cv_results_)\n",
    "smote_pivot_table = smote_results.pivot_table(index='param_complementnb__alpha', \n",
    "                                     values=['mean_train_accuracy', 'mean_test_accuracy', \n",
    "                                             'mean_train_precision', 'mean_test_precision',\n",
    "                                             'mean_train_recall', 'mean_test_recall',\n",
    "                                             'mean_train_f1_score', 'mean_test_f1_score'])\n",
    "\n",
    "print(\"Grid Search Results:\")\n",
    "print(smote_pivot_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec655acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "adasyn_final_cnb_model = make_pipeline(ADASYN(n_neighbors=5, random_state=2727), \n",
    "                                    ComplementNB(alpha = 0.00001))\n",
    "adasyn_final_cnb_model.fit(Xtrain, labels_train)\n",
    "Xtest_cnb = adasyn_final_cnb_model.predict(Xtest)\n",
    "f1_adasyn_final = metrics.f1_score(labels_eval, Xtest_cnb)\n",
    "acc_adasyn_final = metrics.accuracy_score(labels_eval, Xtest_cnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ae32690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search Results:\n",
      "                           mean_test_accuracy  mean_test_f1_score  \\\n",
      "param_complementnb__alpha                                           \n",
      "0.00001                              0.704333            0.520227   \n",
      "0.00010                              0.704237            0.520146   \n",
      "0.00100                              0.704092            0.519974   \n",
      "0.10000                              0.703756            0.519715   \n",
      "1.00000                              0.703387            0.519505   \n",
      "\n",
      "                           mean_test_precision  mean_test_recall  \\\n",
      "param_complementnb__alpha                                          \n",
      "0.00001                               0.408522          0.716054   \n",
      "0.00010                               0.408422          0.716054   \n",
      "0.00100                               0.408256          0.715911   \n",
      "0.10000                               0.407914          0.715982   \n",
      "1.00000                               0.407562          0.716269   \n",
      "\n",
      "                           mean_train_accuracy  mean_train_f1_score  \\\n",
      "param_complementnb__alpha                                             \n",
      "0.00001                               0.704809             0.521323   \n",
      "0.00010                               0.704709             0.521238   \n",
      "0.00100                               0.704597             0.521125   \n",
      "0.10000                               0.704261             0.520809   \n",
      "1.00000                               0.703948             0.520552   \n",
      "\n",
      "                           mean_train_precision  mean_train_recall  \n",
      "param_complementnb__alpha                                           \n",
      "0.00001                                0.409214           0.718041  \n",
      "0.00010                                0.409110           0.718041  \n",
      "0.00100                                0.408988           0.717987  \n",
      "0.10000                                0.408629           0.717898  \n",
      "1.00000                                0.408306           0.717916  \n"
     ]
    }
   ],
   "source": [
    "#SMOTE\n",
    "\n",
    "imba_pipeline = make_pipeline(SMOTE(random_state=2727), \n",
    "                                    ComplementNB())\n",
    "param_grid = {\n",
    "    'complementnb__alpha': alpha_list  \n",
    "}\n",
    "\n",
    "grid_imba = GridSearchCV(imba_pipeline, param_grid=param_grid, cv=5, scoring=scorers,\n",
    "                        return_train_score=True,refit=False)\n",
    "smote_grid = grid_imba.fit(Xtrain, labels_train)\n",
    "smote_results = pd.DataFrame(smote_grid.cv_results_)\n",
    "smote_pivot_table = smote_results.pivot_table(index='param_complementnb__alpha', \n",
    "                                     values=['mean_train_accuracy', 'mean_test_accuracy', \n",
    "                                             'mean_train_precision', 'mean_test_precision',\n",
    "                                             'mean_train_recall', 'mean_test_recall',\n",
    "                                             'mean_train_f1_score', 'mean_test_f1_score'])\n",
    "\n",
    "print(\"Grid Search Results:\")\n",
    "print(smote_pivot_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7d838a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_final_cnb_model = make_pipeline(SMOTE(random_state=2727), \n",
    "                                    ComplementNB(alpha = 0.00001))\n",
    "smote_final_cnb_model.fit(Xtrain, labels_train)\n",
    "Xtest_cnb = smote_final_cnb_model.predict(Xtest)\n",
    "f1_smote_final = metrics.f1_score(labels_eval, Xtest_cnb)\n",
    "acc_smote_final = metrics.accuracy_score(labels_eval, Xtest_cnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1246732e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score for model using ADASYN: 0.5374535497750831\n",
      "F1-score for model using SMOTE: 0.5190245953331932\n"
     ]
    }
   ],
   "source": [
    "print(\"F1-score for model using ADASYN:\", f1_adasyn_final)\n",
    "print(\"F1-score for model using SMOTE:\", f1_smote_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c514201f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for model using ADASYN: 0.6968531692623213\n",
      "Accuracy for model using SMOTE: 0.7067230660770365\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for model using ADASYN:\", acc_adasyn_final)\n",
    "print(\"Accuracy for model using SMOTE:\", acc_smote_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f192ec24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nOversampling improved the model performance. \\nADASYN is better in terms of F1-score, while SMOTE is better in terms of accuracy.\\nHowever, considering the perfomance of F1-score is more important for the imbalanced dataset, the optimal model in this case\\nwould be Complement Naive Bayes with ADASYN as the oversampling method.\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Oversampling improved the model performance. \n",
    "ADASYN is better in terms of F1-score, while SMOTE is better in terms of accuracy.\n",
    "However, considering the perfomance of F1-score is more important for the imbalanced dataset, the optimal model in this case\n",
    "would be Complement Naive Bayes with ADASYN as the oversampling method.\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
